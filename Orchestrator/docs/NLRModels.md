## 									-- DRAFT --



# Natural Language Representation Model


Natural Language Representation models are generic language representation models which have been trained towards more sophisticated pretraining tasks for both monolingual as well as multilingual scenarios. Turing NLR models are used as a natural replacement for BERT-like models.

## Models

**TBD**: Describe models in [versions repository][2].



## References

* [UniLMv2 Paper][1]

* [NLR Versions Repository][2]

* 

[1]: https://arxiv.org/abs/2002.12804 "UniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training"
[2]: https://aka.ms/nlrversions

